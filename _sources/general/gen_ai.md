# AI Tools

Recent generative AI tools have reached an impressive level of performance. In particular, large language models (e.g., GPT-4) show an impressive ability to generate text, and tools like ChatGPT make it easy to prompt and interact with such models. We are open minded about the use of such tools during the ExPra. We believe such tools can be useful, but may also impede learning and assessment if not used responsibly.

We are having to adapt the way that we design and evaluate assessments to ensure that we are assessing your knowledge and ability, and not participating in a Turing test.

## Uses of AI we will allow within reason

We will **allow** usage of AI tools in some cases, if you find it useful:

* Rephrasing text and spelling/grammar check (e.g., DeepL Write, Grammarly)

* Translating text (e.g., DeepL Translator)

* Literature search & article summary (e.g., Elicit) alongside independent reading

* 'Brainstorming' on a topic (e.g., using ChatGPT)

* (Image generation, e.g., DALL-E)

## Rules for usage of AI

* Your own contribution in writing the reports must exceed the contribution by AI (i.e., having an AI tool write entire parts of the reports is not acceptable).

* You are responsible for the reports you submit – you must check any output (text, code, etc.) created and sources cited by AI. Using AI tools uncritically is likely going to result in errors.

* AI tools cannot be used as a citable source (e.g., “According to ChatGPT (2024), priming is a psychological phenomenon…”). Any claims you make must be supported by citations of peer-reviewed publications.

* You must provide a list of AI tools they used at the end of their report (after the reference list). This list should include:
    1. Name, version and provider of the tool (company, organization or person that offers or programmed the tool)
    2. Purpose of using the tool (e.g., translation, rephrasing, grammar/spelling check)
    3. Affected text segments (e.g., “Discussion section” or “p. 14-15”)
    4. Date of content generation
    5. Address (URL of the tool)

* You must add the following to your declaration of originality (*Eigenständigkeitserklärung; for a template see [FAQs by the examination office](https://www.psychologie.uni-frankfurt.de/126118252/BSc_MSc_FAQ_Okt_2022.pdf)*):
    > I am aware that the use of machine-generated texts does not guarantee the quality of content and text. I therefore declare that I have only used text-generating AI tools as an aid and that my creative influence predominates in this work. Furthermore, I declare that I have documented all text passages that were written with the aid of AI-supported programs accordingly and provided a reference to the AI-supported program used. I declare that I have not used any AI writing tools whose use the examiner has explicitly excluded in writing.

## Recommendations in case we get it wrong

There is no reliable method for detecting the use of AI, but we are required to report any suspicions of deception to the examination board. As a result, there is a chance we might get it wrong.

To avoid this situation, we very highly recommend the following steps, so that you will be able to demonstrate that your report is your own work:

* Save separate versions of your report, with time stamps, on a daily basis.

* Save all input prompts and outputs created by any AI tools that you used.

## Tips for Using Large Language Models in Academia

One particular difficulty with tools like ChatGPT is that they can produce outputs that appear highly fluent and confident, even when the output is wrong. While tools like this can be useful for brainstorming, any suggestions they make must be checked thoroughly.

These models are trained on large amounts of text available on the internet, and are trained to generate new text like that they have seen before. This will include some trustworthy academic sources, but also text from (e.g.,) forum interactions, blog posts, pop science articles, etc.. Just as you would not uncritically trust or cite such sources, you should not uncritically trust or cite the output from platforms like ChatGPT.

Common issues with large language models:

* Citations that these models produce can be either "hallucinated" (made up) or misattributed (the source they cite didn't really say what the output claims).

* Outputs can be wrong in more subtle ways, such as conflating concepts, failing to evaluate the consequences of some code, or just misunderstanding the purpose of a prompt.

If you prompt a large language model, in addition to the info above, we recommend that you:

1. Check any citations or sources it provides - did those researchers really say or find what the output claims?

2. Try to find original sources that discuss and evaluate research relevant to the output's claims. The output will often provide key words that you can use in your literature searches.

3. Do independent research into any topics or research you are not already familiar with, to make sure you understand it yourself, so that you avoid reproducing misunderstandings in the output.

4. Reflect critically on the output, and relate it to your own knowledge.

##### Acknowledgements

Parts of this text are adapted from text by Sandro Wiesmann, and informed by a guide by [Goethe University Lehre virtuell](https://lehre-virtuell.uni-frankfurt.de/knowhow/einsatz-von-generativer-ki-in-der-lehre-handlungsempfehlungen-fur-lehrende/).
